# DeepSeek LLM Provider ä½¿ç”¨æŒ‡å—

æœ¬æ–‡æ¡£å±•ç¤ºäº†å¦‚ä½•åœ¨Cluster Nodeæ¶æ„ä¸­ä½¿ç”¨æ–°å®ç°çš„DeepSeek LLM SubNodeProviderã€‚

## æ¦‚è¿°

DeepSeek LLM Provideræ˜¯Cluster Nodeæ¶æ„ä¸­LLM SubNodeProviderçš„å…·ä½“å®ç°ï¼Œæä¾›äº†ä¸DeepSeek APIé›†æˆçš„å®Œæ•´åŠŸèƒ½ã€‚

## ä¸»è¦ç‰¹æ€§

- âœ… **å®Œæ•´çš„SubNodeProvideræ¥å£å®ç°**ï¼šæ”¯æŒLLM SubNodeProviderçš„æ‰€æœ‰æ–¹æ³•
- âœ… **é…ç½®ç®¡ç†**ï¼šæ”¯æŒæ¨¡å‹é€‰æ‹©ã€APIå¯†é’¥ã€æ¸©åº¦ç­‰å‚æ•°é…ç½®
- âœ… **NodeRegistryé›†æˆ**ï¼šå¯ä»¥æ³¨å†Œåˆ°NodeRegistryè¿›è¡Œç»Ÿä¸€ç®¡ç†
- âœ… **GraphFlowä»»åŠ¡é›†æˆ**ï¼šå¯ä»¥ä½œä¸ºGraphFlowä»»åŠ¡æ‰§è¡Œ
- âœ… **ç±»å‹å®‰å…¨**ï¼šä½¿ç”¨Rustç±»å‹ç³»ç»Ÿç¡®ä¿ç¼–è¯‘æ—¶å®‰å…¨
- âœ… **å¼‚æ­¥æ”¯æŒ**ï¼šæ‰€æœ‰æ“ä½œéƒ½æ˜¯å¼‚æ­¥çš„
- âœ… **é”™è¯¯å¤„ç†**ï¼šå®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶

## åŸºæœ¬ä½¿ç”¨

### 1. åˆ›å»ºDeepSeek Provider

```rust
use hetumind_core::workflow::providers::{DeepSeekLLMProvider, DeepSeekConfig, create_deepseek_provider};

// ä½¿ç”¨é»˜è®¤é…ç½®
let provider = DeepSeekLLMProvider::new(DeepSeekConfig::default());

// ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
let config = DeepSeekConfig {
    model: "deepseek-chat".to_string(),
    api_key: Some("your-api-key".to_string()),
    max_tokens: Some(4096),
    temperature: Some(0.7),
    top_p: Some(95.0),
    ..Default::default()
};

let provider = DeepSeekLLMProvider::new(config);

// æˆ–è€…ä½¿ç”¨å·¥å‚å‡½æ•°
let provider = create_deepseek_provider(Some(config))?;
```

### 2. åˆå§‹åŒ–Provider

```rust
// åˆå§‹åŒ–Providerä¼šéªŒè¯APIå¯†é’¥çš„æœ‰æ•ˆæ€§
provider.initialize().await?;

// å¦‚æœAPIå¯†é’¥æ— æ•ˆï¼Œä¼šè¿”å›NodeExecutionError
```

### 3. è°ƒç”¨LLM

```rust
use hetumind_core::workflow::sub_node_provider::{LLMConfig, Message};

// å‡†å¤‡æ¶ˆæ¯
let messages = vec![
    Message {
        role: "user".to_string(),
        content: "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹Rustç¼–ç¨‹è¯­è¨€ã€‚".to_string(),
    }
];

// é…ç½®LLMè°ƒç”¨
let llm_config = LLMConfig {
    model: "deepseek-chat".to_string(),
    max_tokens: Some(1000),
    temperature: Some(0.7),
    top_p: Some(90),
    stop_sequences: Some(vec!["\n\nHuman:".to_string()]),
    api_key: Some("your-api-key".to_string()),
};

// è°ƒç”¨LLM
let response = provider.call_llm(messages, llm_config).await?;

println!("å›å¤: {}", response.content);
println!("ä½¿ç”¨ç»Ÿè®¡: {:?}", response.usage);
```

## é«˜çº§ç”¨æ³•

### 1. ä¸NodeRegistryé›†æˆ

```rust
use hetumind_core::workflow::{NodeRegistry, NodeKind};

// åˆ›å»ºNodeRegistry
let node_registry = NodeRegistry::new();

// æ³¨å†ŒDeepSeek Provider
let node_kind: NodeKind = "deepseek_llm".into();
node_registry.register_subnode_provider(node_kind.clone(), provider)?;

// éªŒè¯æ³¨å†ŒæˆåŠŸ
assert!(node_registry.has_subnode_provider(&node_kind));
assert_eq!(node_registry.subnode_provider_count(), 1);

// è·å–æ³¨å†Œçš„Provider
let retrieved_provider = node_registry.get_subnode_provider(&node_kind)?;
```

### 2. ä¸GraphFlowä»»åŠ¡é›†æˆ

```rust
use hetumind_core::workflow::{
    graph_flow_tasks::{ClusterNodeExecutor, Context},
    sub_node_provider::{ClusterNodeConfig, ExecutionConfig},
};

// åˆ›å»ºClusterNodeExecutor
let mut executor = ClusterNodeExecutor::new(node_registry);

// é…ç½®ClusterNode
let cluster_config = ClusterNodeConfig {
    llm_config: Some(LLMConfig {
        model: "deepseek-chat".to_string(),
        max_tokens: Some(500),
        temperature: Some(0.8),
        ..Default::default()
    }),
    memory_config: None,
    tools_config: None,
    execution_config: ExecutionConfig {
        timeout_seconds: Some(30),
        max_retries: Some(3),
        parallel_execution: Some(true),
    },
};

// æ³¨å†ŒProvideråˆ°Executor
executor.register_subnode_provider(node_kind, cluster_config)?;

// æ‰§è¡Œä»»åŠ¡
let task_ids = executor.task_ids();
let mut context = Context::new();
context.set("input_messages", &messages)?;

let result = executor.execute_task(&task_ids[0], context).await?;
println!("ä»»åŠ¡ç»“æœ: {:?}", result.response);
```

### 3. é…ç½®ç®¡ç†

```rust
// åŠ¨æ€æ›´æ–°é…ç½®
let new_config = DeepSeekConfig {
    model: "deepseek-coder".to_string(),
    max_tokens: Some(8000),
    temperature: Some(0.1),
    ..Default::default()
};

provider.update_config(new_config);

// éªŒè¯é…ç½®æ›´æ–°
assert_eq!(provider.config().model, "deepseek-coder");
```

## é…ç½®é€‰é¡¹

### DeepSeekConfig

| å­—æ®µ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `model` | `String` | `"deepseek-chat"` | DeepSeekæ¨¡å‹åç§° |
| `max_tokens` | `Option<u32>` | `Some(4096)` | æœ€å¤§ç”Ÿæˆtokenæ•° |
| `temperature` | `Option<f64>` | `Some(0.7)` | æ¸©åº¦å‚æ•°(0.0-2.0) |
| `top_p` | `Option<f64>` | `Some(1.0)` | Top-pé‡‡æ ·å‚æ•° |
| `stop_sequences` | `Option<Vec<String>>` | `None` | åœæ­¢åºåˆ— |
| `base_url` | `Option<String>` | `None` | APIåŸºç¡€URL |
| `timeout` | `Option<u64>` | `None` | è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’) |
| `api_key` | `Option<String>` | `None` | APIå¯†é’¥ |

### LLMConfig

| å­—æ®µ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `model` | `String` | `"default"` | æ¨¡å‹åç§° |
| `max_tokens` | `Option<u32>` | `None` | æœ€å¤§tokenæ•° |
| `temperature` | `Option<f64>` | `None` | æ¸©åº¦å‚æ•° |
| `top_p` | `Option<u32>` | `None` | Top-på‚æ•° |
| `stop_sequences` | `Option<Vec<String>>` | `None` | åœæ­¢åºåˆ— |
| `api_key` | `Option<String>` | `None` | APIå¯†é’¥ |

## é”™è¯¯å¤„ç†

æ‰€æœ‰æ“ä½œéƒ½è¿”å›`Result<T, NodeExecutionError>`ï¼Œå¸¸è§çš„é”™è¯¯ç±»å‹åŒ…æ‹¬ï¼š

```rust
// APIå¯†é’¥ç›¸å…³é”™è¯¯
NodeExecutionError::ConfigurationError("DeepSeek API key not found")

// å¤–éƒ¨æœåŠ¡é”™è¯¯
NodeExecutionError::ExternalServiceError { service: "DeepSeek API error" }

// æ•°æ®å¤„ç†é”™è¯¯
NodeExecutionError::DataProcessingError { message: "Invalid response format" }
```

## APIå¯†é’¥ç®¡ç†

DeepSeek Provideræ”¯æŒå¤šç§APIå¯†é’¥æ¥æºï¼š

1. **ç›´æ¥é…ç½®**
   ```rust
   let config = DeepSeekConfig {
       api_key: Some("your-api-key".to_string()),
       ..Default::default()
   };
   ```

2. **ç¯å¢ƒå˜é‡**
   ```bash
   export DEEPSEEK_API_KEY="your-api-key"
   ```
   Providerä¼šè‡ªåŠ¨æŸ¥æ‰¾`DEEPSEEK_API_KEY`ç¯å¢ƒå˜é‡ã€‚

3. **è¿è¡Œæ—¶åŠ¨æ€è®¾ç½®**
   ```rust
   let mut provider = DeepSeekLLMProvider::new(DeepSeekConfig::default());
   // ç¨åé€šè¿‡update_configè®¾ç½®APIå¯†é’¥
   ```

## èŠ‚ç‚¹å®šä¹‰

DeepSeek Providerä¼šè‡ªåŠ¨åˆ›å»ºç›¸åº”çš„NodeDefinitionï¼š

- **èŠ‚ç‚¹ç±»å‹**: `deepseek_llm`
- **èŠ‚ç‚¹ç»„**: `Transform` (æ•°æ®è½¬æ¢)
- **ç‰ˆæœ¬**: `1.0.0`
- **å›¾æ ‡**: `robot`
- **å›¾æ ‡é¢œè‰²**: è“è‰²
- **æ–‡æ¡£**: https://platform.deepseek.com/

## æµ‹è¯•

è¿è¡Œæµ‹è¯•ï¼š

```bash
cargo test -p hetumind-core deepseek_provider
```

æµ‹è¯•åŒ…æ‹¬ï¼š
- é…ç½®è½¬æ¢æµ‹è¯•
- Provideråˆ›å»ºæµ‹è¯•
- åˆå§‹åŒ–æµ‹è¯•
- æ¶ˆæ¯è½¬æ¢æµ‹è¯•
- é›†æˆæµ‹è¯•

## ç¤ºä¾‹ä»£ç 

### å®Œæ•´ç¤ºä¾‹

```rust
use hetumind_core::workflow::{
    providers::{DeepSeekLLMProvider, DeepSeekConfig},
    sub_node_provider::{LLMConfig, Message},
    NodeRegistry,
    NodeKind,
    graph_flow_tasks::{ClusterNodeExecutor, Context, ClusterNodeConfig},
};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // 1. åˆ›å»ºé…ç½®
    let config = DeepSeekConfig {
        model: "deepseek-chat".to_string(),
        api_key: Some("your-api-key".to_string()),
        max_tokens: Some(1000),
        temperature: Some(0.7),
        ..Default::default()
    };

    // 2. åˆ›å»ºProvider
    let provider = DeepSeekLLMProvider::new(config);

    // 3. åˆå§‹åŒ–
    provider.initialize().await?;

    // 4. æ³¨å†Œåˆ°NodeRegistry
    let node_registry = NodeRegistry::new();
    let node_kind = "deepseek_llm".into();
    node_registry.register_subnode_provider(node_kind.clone(), provider.clone())?;

    // 5. åˆ›å»ºClusterNodeExecutor
    let mut executor = ClusterNodeExecutor::new(node_registry);

    // 6. é…ç½®ClusterNode
    let cluster_config = ClusterNodeConfig {
        llm_config: Some(LLMConfig {
            model: "deepseek-chat".to_string(),
            max_tokens: Some(500),
            temperature: Some(0.8),
            ..Default::default()
        }),
        ..Default::default()
    };

    // 7. æ³¨å†Œåˆ°Executor
    executor.register_subnode_provider(node_kind, cluster_config)?;

    // 8. å‡†å¤‡æ¶ˆæ¯
    let messages = vec![
        Message {
            role: "user".to_string(),
            content: "è¯·è§£é‡Šä»€ä¹ˆæ˜¯Cluster Nodeæ¶æ„ï¼Ÿ".to_string(),
        }
    ];

    // 9. æ‰§è¡Œä»»åŠ¡
    let task_ids = executor.task_ids();
    let mut context = Context::new();
    context.set("input_messages", &messages)?;

    let result = executor.execute_task(&task_ids[0], context).await?;

    println!("âœ… DeepSeek LLM Provideré›†æˆæµ‹è¯•æˆåŠŸï¼");
    println!("ğŸ“Š ç»“æœ: {:?}", result.response);

    Ok(())
}
```

## æœ€ä½³å®è·µ

1. **APIå¯†é’¥å®‰å…¨**ï¼šä¸è¦å°†APIå¯†é’¥ç¡¬ç¼–ç åœ¨ä»£ç ä¸­ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å®‰å…¨çš„é…ç½®ç®¡ç†ç³»ç»Ÿ
2. **é”™è¯¯å¤„ç†**ï¼šå§‹ç»ˆæ£€æŸ¥å¹¶å¦¥å–„å¤„ç†å¯èƒ½çš„é”™è¯¯
3. **èµ„æºç®¡ç†**ï¼šåŠæ—¶é‡Šæ”¾ä¸å†ä½¿ç”¨çš„Providerå®ä¾‹
4. **é…ç½®éªŒè¯**ï¼šåœ¨åˆå§‹åŒ–æ—¶éªŒè¯é…ç½®çš„æœ‰æ•ˆæ€§
5. **æµ‹è¯•é©±åŠ¨**ï¼šä¸ºå…³é”®åŠŸèƒ½ç¼–å†™å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•

## æ³¨æ„äº‹é¡¹

- å½“å‰ç‰ˆæœ¬ä½¿ç”¨æ¨¡æ‹ŸAPIè°ƒç”¨ï¼Œç”Ÿäº§ç¯å¢ƒéœ€è¦å®ç°çœŸå®çš„HTTPè¯·æ±‚
- ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®šï¼Œé¿å…è¯·æ±‚è¶…æ—¶
- åˆç†è®¾ç½®tokené™åˆ¶ï¼Œé¿å…è¶…å‡ºAPIé…é¢
- å®šæœŸæ›´æ–°APIå¯†é’¥ï¼Œç¡®ä¿è®¿é—®æƒé™

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **APIå¯†é’¥æœªæ‰¾åˆ°**
   - æ£€æŸ¥ç¯å¢ƒå˜é‡`DEEPSEEK_API_KEY`
   - ç¡®è®¤é…ç½®ä¸­çš„`api_key`å­—æ®µ

2. **åˆå§‹åŒ–å¤±è´¥**
   - éªŒè¯APIå¯†é’¥æ ¼å¼æ˜¯å¦æ­£ç¡®
   - æ£€æŸ¥ç½‘ç»œè¿æ¥

3. **é…ç½®è½¬æ¢é”™è¯¯**
   - ç¡®è®¤`LLMConfig`ä¸­çš„`top_p`æ˜¯`u32`ç±»å‹
   - æ£€æŸ¥æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å·²æä¾›

4. **èŠ‚ç‚¹æ³¨å†Œå¤±è´¥**
   - ç¡®è®¤èŠ‚ç‚¹ç±»å‹å”¯ä¸€
   - æ£€æŸ¥NodeRegistryçŠ¶æ€

é€šè¿‡éµå¾ªæœ¬æŒ‡å—ï¼Œæ‚¨å¯ä»¥æˆåŠŸåœ°åœ¨Cluster Nodeæ¶æ„ä¸­é›†æˆå’Œä½¿ç”¨DeepSeek LLM Providerã€‚