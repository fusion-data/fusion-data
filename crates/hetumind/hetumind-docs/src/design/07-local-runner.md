# Hetumind æœ¬åœ°è¿è¡Œå™¨è®¾è®¡

## 1. æœ¬åœ°è¿è¡Œå™¨æ¦‚è¿°

Hetumind æœ¬åœ°è¿è¡Œå™¨æ˜¯ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„ CLI å·¥å…·ï¼Œæä¾›æœ¬åœ°å·¥ä½œæµå¼€å‘ã€æµ‹è¯•å’Œè°ƒè¯•ç¯å¢ƒã€‚å®ƒæ”¯æŒç¦»çº¿è¿è¡Œã€å®æ—¶è°ƒè¯•å’Œæ€§èƒ½åˆ†æï¼Œæ˜¯å¼€å‘è€…çš„é¦–é€‰å·¥å…·ã€‚

### 1.1 è®¾è®¡ç›®æ ‡

- **å¼€å‘å‹å¥½**: æä¾›å®Œæ•´çš„æœ¬åœ°å¼€å‘ç¯å¢ƒ
- **å¿«é€Ÿè¿­ä»£**: æ”¯æŒå·¥ä½œæµçš„å¿«é€Ÿæµ‹è¯•å’Œè°ƒè¯•
- **ç¦»çº¿è¿è¡Œ**: æ— éœ€ç½‘ç»œè¿æ¥å³å¯è¿è¡Œå·¥ä½œæµ
- **æ€§èƒ½åˆ†æ**: å†…ç½®æ€§èƒ½ç›‘æ§å’Œåˆ†æå·¥å…·
- **æ˜“äºä½¿ç”¨**: ç›´è§‚çš„å‘½ä»¤è¡Œç•Œé¢

### 1.2 æ ¸å¿ƒç‰¹æ€§

- å·¥ä½œæµæœ¬åœ°æ‰§è¡Œå’Œè°ƒè¯•
- å®æ—¶æ—¥å¿—å’ŒçŠ¶æ€ç›‘æ§
- æ€§èƒ½åˆ†æå’Œä¼˜åŒ–å»ºè®®
- é…ç½®ç®¡ç†å’Œç¯å¢ƒå˜é‡
- æ’ä»¶ç³»ç»Ÿå’Œæ‰©å±•æ”¯æŒ

## 2. CLI æ¶æ„è®¾è®¡

### 2.1 å‘½ä»¤ç»“æ„

```rust
use clap::{Parser, Subcommand};
use std::path::PathBuf;

#[derive(Parser)]
#[command(name = "hetumind")]
#[command(about = "Hetumind å·¥ä½œæµè‡ªåŠ¨åŒ–æœ¬åœ°è¿è¡Œå™¨")]
#[command(version = "1.0.0")]
pub struct Cli {
    #[command(subcommand)]
    pub command: Commands,

    /// é…ç½®æ–‡ä»¶è·¯å¾„
    #[arg(short, long, global = true)]
    pub config: Option<PathBuf>,

    /// è¯¦ç»†è¾“å‡º
    #[arg(short, long, global = true)]
    pub verbose: bool,

    /// å·¥ä½œç›®å½•
    #[arg(short = 'C', long, global = true)]
    pub directory: Option<PathBuf>,
}

#[derive(Subcommand)]
pub enum Commands {
    /// å·¥ä½œæµç®¡ç†
    Workflow {
        #[command(subcommand)]
        action: WorkflowCommands,
    },
    /// æ‰§è¡Œç®¡ç†
    Execute {
        #[command(subcommand)]
        action: ExecuteCommands,
    },
    /// èŠ‚ç‚¹ç®¡ç†
    Node {
        #[command(subcommand)]
        action: NodeCommands,
    },
    /// å¼€å‘å·¥å…·
    Dev {
        #[command(subcommand)]
        action: DevCommands,
    },
    /// é…ç½®ç®¡ç†
    Config {
        #[command(subcommand)]
        action: ConfigCommands,
    },
}
```

### 2.2 å·¥ä½œæµå‘½ä»¤

```rust
#[derive(Subcommand)]
pub enum WorkflowCommands {
    /// åˆ›å»ºæ–°å·¥ä½œæµ
    New {
        /// å·¥ä½œæµåç§°
        name: String,
        /// æ¨¡æ¿ç±»å‹
        #[arg(short, long)]
        template: Option<String>,
        /// è¾“å‡ºç›®å½•
        #[arg(short, long)]
        output: Option<PathBuf>,
    },
    /// åˆ—å‡ºå·¥ä½œæµ
    List {
        /// è¿‡æ»¤æ¨¡å¼
        #[arg(short, long)]
        filter: Option<String>,
    },
    /// éªŒè¯å·¥ä½œæµ
    Validate {
        /// å·¥ä½œæµæ–‡ä»¶è·¯å¾„
        file: PathBuf,
    },
    /// è¿è¡Œå·¥ä½œæµ
    Run {
        /// å·¥ä½œæµæ–‡ä»¶è·¯å¾„
        file: PathBuf,
        /// è¾“å…¥æ•°æ®æ–‡ä»¶
        #[arg(short, long)]
        input: Option<PathBuf>,
        /// ç¯å¢ƒå˜é‡æ–‡ä»¶
        #[arg(short, long)]
        env: Option<PathBuf>,
        /// è°ƒè¯•æ¨¡å¼
        #[arg(short, long)]
        debug: bool,
        /// ç›‘è§†æ¨¡å¼
        #[arg(short, long)]
        watch: bool,
    },
    /// å¯¼å‡ºå·¥ä½œæµ
    Export {
        /// å·¥ä½œæµæ–‡ä»¶è·¯å¾„
        file: PathBuf,
        /// å¯¼å‡ºæ ¼å¼
        #[arg(short, long, default_value = "json")]
        format: ExportFormat,
        /// è¾“å‡ºæ–‡ä»¶
        #[arg(short, long)]
        output: Option<PathBuf>,
    },
}

#[derive(Clone, ValueEnum)]
pub enum ExportFormat {
    Json,
    Yaml,
    Toml,
}
```

### 2.3 æ‰§è¡Œå‘½ä»¤

```rust
#[derive(Subcommand)]
pub enum ExecuteCommands {
    /// è¿è¡Œå•ä¸ªèŠ‚ç‚¹
    Node {
        /// èŠ‚ç‚¹ç±»å‹
        node_type: String,
        /// èŠ‚ç‚¹å‚æ•°æ–‡ä»¶
        #[arg(short, long)]
        params: Option<PathBuf>,
        /// è¾“å…¥æ•°æ®æ–‡ä»¶
        #[arg(short, long)]
        input: Option<PathBuf>,
    },
    /// äº¤äº’å¼æ‰§è¡Œ
    Interactive {
        /// å·¥ä½œæµæ–‡ä»¶è·¯å¾„
        file: PathBuf,
    },
    /// æ‰¹é‡æ‰§è¡Œ
    Batch {
        /// å·¥ä½œæµæ–‡ä»¶è·¯å¾„
        file: PathBuf,
        /// è¾“å…¥æ•°æ®ç›®å½•
        #[arg(short, long)]
        input_dir: PathBuf,
        /// è¾“å‡ºç›®å½•
        #[arg(short, long)]
        output_dir: PathBuf,
        /// å¹¶å‘æ•°
        #[arg(short, long, default_value = "4")]
        concurrency: usize,
    },
    /// æ€§èƒ½æµ‹è¯•
    Benchmark {
        /// å·¥ä½œæµæ–‡ä»¶è·¯å¾„
        file: PathBuf,
        /// æµ‹è¯•æ¬¡æ•°
        #[arg(short, long, default_value = "10")]
        iterations: usize,
        /// è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶
        #[arg(short, long)]
        report: Option<PathBuf>,
    },
}
```

## 3. æœ¬åœ°æ‰§è¡Œå¼•æ“

### 3.1 æœ¬åœ°æ‰§è¡Œå™¨

```rust
use tokio::sync::mpsc;
use std::collections::HashMap;

pub struct LocalWorkflowRunner {
    /// èŠ‚ç‚¹æ³¨å†Œè¡¨
    node_registry: Arc<NodeRegistry>,
    /// é…ç½®ç®¡ç†å™¨
    config_manager: Arc<ConfigManager>,
    /// äº‹ä»¶å‘é€å™¨
    event_sender: mpsc::UnboundedSender<ExecutionEvent>,
    /// è°ƒè¯•æ¨¡å¼
    debug_mode: bool,
}

impl LocalWorkflowRunner {
    pub fn new(config: LocalRunnerConfig) -> Self {
        let (event_sender, _) = mpsc::unbounded_channel();

        Self {
            node_registry: Arc::new(NodeRegistry::new()),
            config_manager: Arc::new(ConfigManager::new(config.config_path)),
            event_sender,
            debug_mode: config.debug_mode,
        }
    }

    pub async fn run_workflow(
        &self,
        workflow_file: &Path,
        input_data: Option<Vec<ExecutionData>>,
        env_vars: HashMap<String, String>,
    ) -> Result<ExecutionResult, LocalRunnerError> {
        // åŠ è½½å·¥ä½œæµå®šä¹‰
        let workflow = self.load_workflow(workflow_file).await?;

        // éªŒè¯å·¥ä½œæµ
        self.validate_workflow(&workflow)?;

        // åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
        let execution_context = ExecutionContext {
            execution_id: Uuid::now_v7(),
            workflow: workflow.clone(),
            current_node_id: Uuid::now_v7(),
            input_data: input_data.unwrap_or_default(),
            started_at: Utc::now(),
            mode: ExecutionMode::Local,
            user_id: None,
            env_vars,
        };

        // åˆ›å»ºæœ¬åœ°æ‰§è¡Œå¼•æ“
        let engine = LocalExecutionEngine::new(
            self.node_registry.clone(),
            self.event_sender.clone(),
            self.debug_mode,
        );

        // æ‰§è¡Œå·¥ä½œæµ
        engine.execute_workflow(&workflow, &execution_context).await
    }

    async fn load_workflow(&self, file_path: &Path) -> Result<Workflow, LocalRunnerError> {
        let content = tokio::fs::read_to_string(file_path).await?;

        match file_path.extension().and_then(|s| s.to_str()) {
            Some("json") => serde_json::from_str(&content)
                .map_err(|e| LocalRunnerError::ParseError(e.to_string())),
            Some("yaml") | Some("yml") => serde_yaml::from_str(&content)
                .map_err(|e| LocalRunnerError::ParseError(e.to_string())),
            Some("toml") => toml::from_str(&content)
                .map_err(|e| LocalRunnerError::ParseError(e.to_string())),
            _ => Err(LocalRunnerError::UnsupportedFormat),
        }
    }

    fn validate_workflow(&self, workflow: &Workflow) -> Result<(), LocalRunnerError> {
        // éªŒè¯èŠ‚ç‚¹ç±»å‹æ˜¯å¦å­˜åœ¨
        for node in &workflow.nodes {
            if !self.node_registry.has_node(&node.kind) {
                return Err(LocalRunnerError::UnknownNodeType(node.kind.clone()));
            }
        }

        // éªŒè¯è¿æ¥çš„æœ‰æ•ˆæ€§
        for connection in &workflow.connections {
            let source_exists = workflow.nodes.iter()
                .any(|n| n.id == connection.source_node_id);
            let target_exists = workflow.nodes.iter()
                .any(|n| n.id == connection.target_node_id);

            if !source_exists || !target_exists {
                return Err(LocalRunnerError::InvalidConnection);
            }
        }

        Ok(())
    }
}
```

### 3.2 æœ¬åœ°æ‰§è¡Œå¼•æ“

```rust
pub struct LocalExecutionEngine {
    node_registry: Arc<NodeRegistry>,
    event_sender: mpsc::UnboundedSender<ExecutionEvent>,
    debug_mode: bool,
    execution_state: Arc<RwLock<HashMap<NodeId, NodeExecutionState>>>,
}

impl LocalExecutionEngine {
    pub async fn execute_workflow(
        &self,
        workflow: &Workflow,
        context: &ExecutionContext,
    ) -> Result<ExecutionResult, LocalRunnerError> {
        let start_time = Instant::now();

        // å‘é€æ‰§è¡Œå¼€å§‹äº‹ä»¶
        self.send_event(ExecutionEvent {
            event_type: ExecutionEventType::ExecutionStarted,
            execution_id: context.execution_id,
            workflow_id: workflow.id,
            user_id: context.user_id.unwrap_or_default(),
            timestamp: Utc::now(),
            data: serde_json::json!({
                "workflow_name": workflow.name,
                "node_count": workflow.nodes.len(),
            }),
        });

        // æ„å»ºæ‰§è¡Œå›¾
        let execution_graph = self.build_execution_graph(workflow)?;

        // æ‰§è¡ŒèŠ‚ç‚¹
        let mut execution_results = HashMap::default();
        let mut pending_nodes = execution_graph.get_start_nodes();

        while !pending_nodes.is_empty() {
            let mut next_nodes = Vec::new();

            // å¹¶å‘æ‰§è¡Œå½“å‰å±‚çš„èŠ‚ç‚¹
            let tasks: Vec<_> = pending_nodes.into_iter().map(|node_name| {
                let node = workflow.nodes.iter()
                    .find(|n| n.id == node_name)
                    .unwrap()
                    .clone();

                self.execute_node(node, context, &execution_results)
            }).collect();

            let results = futures::future::join_all(tasks).await;

            for (i, result) in results.into_iter().enumerate() {
                match result {
                    Ok(node_result) => {
                        execution_results.insert(node_result.node_name, node_result.clone());

                        // è·å–ä¸‹ä¸€å±‚å¯æ‰§è¡Œçš„èŠ‚ç‚¹
                        let next = execution_graph.get_next_nodes(node_result.node_name);
                        next_nodes.extend(next);

                        if self.debug_mode {
                            println!("âœ“ èŠ‚ç‚¹ {} æ‰§è¡Œå®Œæˆ", node_result.node_name);
                        }
                    }
                    Err(e) => {
                        eprintln!("âœ— èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {}", e);
                        return Err(e);
                    }
                }
            }

            pending_nodes = next_nodes;
        }

        let duration = start_time.elapsed();

        // å‘é€æ‰§è¡Œå®Œæˆäº‹ä»¶
        self.send_event(ExecutionEvent {
            event_type: ExecutionEventType::ExecutionCompleted,
            execution_id: context.execution_id,
            workflow_id: workflow.id,
            user_id: context.user_id.unwrap_or_default(),
            timestamp: Utc::now(),
            data: serde_json::json!({
                "duration_ms": duration.as_millis(),
                "nodes_executed": execution_results.len(),
            }),
        });

        Ok(ExecutionResult {
            execution_id: context.execution_id,
            workflow_id: workflow.id,
            status: ExecutionStatus::Success,
            started_at: context.started_at,
            finished_at: Some(Utc::now()),
            duration: Some(duration),
            node_results: execution_results,
            error: None,
        })
    }

    async fn execute_node(
        &self,
        node: Node,
        context: &ExecutionContext,
        previous_results: &HashMap<NodeId, NodeExecutionResult>,
    ) -> Result<NodeExecutionResult, LocalRunnerError> {
        let start_time = Instant::now();

        // å‘é€èŠ‚ç‚¹å¼€å§‹äº‹ä»¶
        self.send_event(ExecutionEvent {
            event_type: ExecutionEventType::NodeStarted,
            execution_id: context.execution_id,
            workflow_id: context.workflow.id,
            user_id: context.user_id.unwrap_or_default(),
            timestamp: Utc::now(),
            data: serde_json::json!({
                "node_name": node.id,
                "node_type": node.kind,
                "node_name": node.name,
            }),
        });

        // è·å–èŠ‚ç‚¹æ‰§è¡Œå™¨
        let executor = self.node_registry.get_executor(&node.kind)
            .ok_or_else(|| LocalRunnerError::UnknownNodeType(node.kind.clone()))?;

        // å‡†å¤‡è¾“å…¥æ•°æ®
        let input_data = self.prepare_node_input(&node, previous_results, context)?;

        // åˆ›å»ºèŠ‚ç‚¹æ‰§è¡Œä¸Šä¸‹æ–‡
        let node_context = ExecutionContext {
            current_node_id: node.id,
            input_data,
            ..context.clone()
        };

        // æ‰§è¡ŒèŠ‚ç‚¹
        let result = match executor.execute(&node_context, &node).await {
            Ok(output_data) => {
                let duration = start_time.elapsed();

                if self.debug_mode {
                    println!("èŠ‚ç‚¹ {} ({}) æ‰§è¡ŒæˆåŠŸï¼Œè€—æ—¶: {:?}",
                        node.name, node.kind, duration);
                    println!("è¾“å‡ºæ•°æ®: {}", serde_json::to_string_pretty(&output_data).unwrap());
                }

                NodeExecutionResult {
                    node_name: node.id,
                    status: ExecutionStatus::Success,
                    started_at: node_context.started_at,
                    finished_at: Some(Utc::now()),
                    duration: Some(duration),
                    input_data: node_context.input_data,
                    output_data,
                    error: None,
                }
            }
            Err(e) => {
                let duration = start_time.elapsed();

                if self.debug_mode {
                    eprintln!("èŠ‚ç‚¹ {} ({}) æ‰§è¡Œå¤±è´¥: {}",
                        node.name, node.kind, e);
                }

                NodeExecutionResult {
                    node_name: node.id,
                    status: ExecutionStatus::Failed,
                    started_at: node_context.started_at,
                    finished_at: Some(Utc::now()),
                    duration: Some(duration),
                    input_data: node_context.input_data,
                    output_data: vec![],
                    error: Some(e.to_string()),
                }
            }
        };

        // å‘é€èŠ‚ç‚¹å®Œæˆäº‹ä»¶
        self.send_event(ExecutionEvent {
            event_type: if result.status == ExecutionStatus::Success {
                ExecutionEventType::NodeCompleted
            } else {
                ExecutionEventType::NodeFailed
            },
            execution_id: context.execution_id,
            workflow_id: context.workflow.id,
            user_id: context.user_id.unwrap_or_default(),
            timestamp: Utc::now(),
            data: serde_json::json!({
                "node_name": node.id,
                "duration_ms": result.duration.map(|d| d.as_millis()),
                "error": result.error,
            }),
        });

        Ok(result)
    }
}
```

## 4. å¼€å‘å·¥å…·

### 4.1 äº¤äº’å¼è°ƒè¯•å™¨

```rust
use crossterm::{
    event::{self, Event, KeyCode},
    terminal::{disable_raw_mode, enable_raw_mode},
};
use ratatui::{
    backend::CrosstermBackend,
    layout::{Constraint, Direction, Layout},
    widgets::{Block, Borders, List, ListItem, Paragraph},
    Terminal,
};

pub struct InteractiveDebugger {
    workflow: Workflow,
    execution_state: ExecutionState,
    current_node: Option<NodeId>,
    breakpoints: HashSet<NodeId>,
}

impl InteractiveDebugger {
    pub async fn start_debug_session(
        &mut self,
        workflow_file: &Path,
    ) -> Result<(), LocalRunnerError> {
        // åˆå§‹åŒ–ç»ˆç«¯
        enable_raw_mode()?;
        let mut stdout = std::io::stdout();
        crossterm::execute!(stdout, crossterm::terminal::EnterAlternateScreen)?;
        let backend = CrosstermBackend::new(stdout);
        let mut terminal = Terminal::new(backend)?;

        // åŠ è½½å·¥ä½œæµ
        self.workflow = self.load_workflow(workflow_file).await?;

        // ä¸»è°ƒè¯•å¾ªç¯
        loop {
            // ç»˜åˆ¶ç•Œé¢
            terminal.draw(|f| self.draw_debug_ui(f))?;

            // å¤„ç†ç”¨æˆ·è¾“å…¥
            if let Event::Key(key) = event::read()? {
                match key.code {
                    KeyCode::Char('q') => break,
                    KeyCode::Char('n') => self.step_next().await?,
                    KeyCode::Char('c') => self.continue_execution().await?,
                    KeyCode::Char('b') => self.toggle_breakpoint(),
                    KeyCode::Char('r') => self.restart_execution().await?,
                    _ => {}
                }
            }
        }

        // æ¸…ç†ç»ˆç«¯
        disable_raw_mode()?;
        crossterm::execute!(
            terminal.backend_mut(),
            crossterm::terminal::LeaveAlternateScreen
        )?;

        Ok(())
    }

    fn draw_debug_ui(&self, f: &mut ratatui::Frame) {
        let chunks = Layout::default()
            .direction(Direction::Vertical)
            .constraints([
                Constraint::Percentage(30),
                Constraint::Percentage(40),
                Constraint::Percentage(30),
            ])
            .split(f.size());

        // å·¥ä½œæµæ¦‚è§ˆ
        let workflow_block = Block::default()
            .title("å·¥ä½œæµæ¦‚è§ˆ")
            .borders(Borders::ALL);
        let workflow_info = Paragraph::new(format!(
            "åç§°: {}\nèŠ‚ç‚¹æ•°: {}\nè¿æ¥æ•°: {}",
            self.workflow.name,
            self.workflow.nodes.len(),
            self.workflow.connections.len()
        ))
        .block(workflow_block);
        f.render_widget(workflow_info, chunks[0]);

        // èŠ‚ç‚¹åˆ—è¡¨
        let nodes_block = Block::default()
            .title("èŠ‚ç‚¹åˆ—è¡¨")
            .borders(Borders::ALL);
        let node_items: Vec<ListItem> = self.workflow.nodes.iter()
            .map(|node| {
                let status = if Some(node.id) == self.current_node {
                    "â–¶ "
                } else if self.breakpoints.contains(&node.id) {
                    "â— "
                } else {
                    "  "
                };
                ListItem::new(format!("{}{} ({})", status, node.name, node.kind))
            })
            .collect();
        let nodes_list = List::new(node_items).block(nodes_block);
        f.render_widget(nodes_list, chunks[1]);

        // æ§åˆ¶é¢æ¿
        let controls_block = Block::default()
            .title("æ§åˆ¶é¢æ¿")
            .borders(Borders::ALL);
        let controls_text = "å¿«æ·é”®:\n\
            n - å•æ­¥æ‰§è¡Œ\n\
            c - ç»§ç»­æ‰§è¡Œ\n\
            b - åˆ‡æ¢æ–­ç‚¹\n\
            r - é‡æ–°å¼€å§‹\n\
            q - é€€å‡º";
        let controls = Paragraph::new(controls_text).block(controls_block);
        f.render_widget(controls, chunks[2]);
    }
}
```

### 4.2 æ€§èƒ½åˆ†æå™¨

```rust
pub struct PerformanceProfiler {
    execution_metrics: HashMap<NodeId, NodeMetrics>,
    workflow_metrics: WorkflowMetrics,
    start_time: Instant,
}

#[derive(Debug, Clone)]
pub struct NodeMetrics {
    pub execution_count: u64,
    pub total_duration: Duration,
    pub avg_duration: Duration,
    pub min_duration: Duration,
    pub max_duration: Duration,
    pub memory_usage: u64,
    pub cpu_usage: f64,
}

#[derive(Debug, Clone)]
pub struct WorkflowMetrics {
    pub total_executions: u64,
    pub successful_executions: u64,
    pub failed_executions: u64,
    pub avg_execution_time: Duration,
    pub throughput: f64, // executions per second
}

impl PerformanceProfiler {
    pub fn new() -> Self {
        Self {
            execution_metrics: HashMap::default(),
            workflow_metrics: WorkflowMetrics::default(),
            start_time: Instant::now(),
        }
    }

    pub fn record_node_execution(
        &mut self,
        node_name: NodeId,
        duration: Duration,
        memory_usage: u64,
        cpu_usage: f64,
    ) {
        let metrics = self.execution_metrics.entry(node_name).or_insert_with(|| {
            NodeMetrics {
                execution_count: 0,
                total_duration: Duration::ZERO,
                avg_duration: Duration::ZERO,
                min_duration: Duration::MAX,
                max_duration: Duration::ZERO,
                memory_usage: 0,
                cpu_usage: 0.0,
            }
        });

        metrics.execution_count += 1;
        metrics.total_duration += duration;
        metrics.avg_duration = metrics.total_duration / metrics.execution_count as u32;
        metrics.min_duration = metrics.min_duration.min(duration);
        metrics.max_duration = metrics.max_duration.max(duration);
        metrics.memory_usage = metrics.memory_usage.max(memory_usage);
        metrics.cpu_usage = (metrics.cpu_usage + cpu_usage) / 2.0;
    }

    pub fn generate_report(&self) -> PerformanceReport {
        let total_time = self.start_time.elapsed();

        PerformanceReport {
            workflow_metrics: self.workflow_metrics.clone(),
            node_metrics: self.execution_metrics.clone(),
            total_time,
            recommendations: self.generate_recommendations(),
        }
    }

    fn generate_recommendations(&self) -> Vec<String> {
        let mut recommendations = Vec::new();

        // åˆ†ææ…¢èŠ‚ç‚¹
        for (node_name, metrics) in &self.execution_metrics {
            if metrics.avg_duration > Duration::from_secs(5) {
                recommendations.push(format!(
                    "èŠ‚ç‚¹ {} å¹³å‡æ‰§è¡Œæ—¶é—´è¾ƒé•¿ ({:?})ï¼Œå»ºè®®ä¼˜åŒ–",
                    node_name, metrics.avg_duration
                ));
            }

            if metrics.memory_usage > 1024 * 1024 * 100 { // 100MB
                recommendations.push(format!(
                    "èŠ‚ç‚¹ {} å†…å­˜ä½¿ç”¨é‡è¾ƒé«˜ ({} MB)ï¼Œå»ºè®®æ£€æŸ¥å†…å­˜æ³„æ¼",
                    node_name, metrics.memory_usage / 1024 / 1024
                ));
            }
        }

        recommendations
    }
}
```

## 5. é…ç½®ç®¡ç†

### 5.1 é…ç½®ç³»ç»Ÿ

```rust
use serde::{Deserialize, Serialize};
use std::path::PathBuf;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LocalRunnerConfig {
    /// å·¥ä½œç›®å½•
    pub workspace: PathBuf,
    /// æ—¥å¿—çº§åˆ«
    pub log_level: String,
    /// è°ƒè¯•æ¨¡å¼
    pub debug_mode: bool,
    /// å¹¶å‘é™åˆ¶
    pub max_concurrency: usize,
    /// ç¯å¢ƒå˜é‡
    pub env_vars: HashMap<String, String>,
    /// èŠ‚ç‚¹é…ç½®
    pub node_configs: HashMap<String, serde_json::Value>,
    /// æ’ä»¶ç›®å½•
    pub plugin_dirs: Vec<PathBuf>,
}

impl Default for LocalRunnerConfig {
    fn default() -> Self {
        Self {
            workspace: PathBuf::from("."),
            log_level: "info".to_string(),
            debug_mode: false,
            max_concurrency: num_cpus::get(),
            env_vars: HashMap::default(),
            node_configs: HashMap::default(),
            plugin_dirs: vec![PathBuf::from("./plugins")],
        }
    }
}

pub struct ConfigManager {
    config_path: PathBuf,
    config: LocalRunnerConfig,
}

impl ConfigManager {
    pub fn new(config_path: Option<PathBuf>) -> Self {
        let config_path = config_path.unwrap_or_else(|| {
            dirs::config_dir()
                .unwrap_or_else(|| PathBuf::from("."))
                .join("hetumind")
                .join("config.toml")
        });

        let config = Self::load_config(&config_path)
            .unwrap_or_default();

        Self { config_path, config }
    }

    fn load_config(path: &Path) -> Result<LocalRunnerConfig, ConfigError> {
        if !path.exists() {
            return Ok(LocalRunnerConfig::default());
        }

        let content = std::fs::read_to_string(path)?;
        toml::from_str(&content).map_err(ConfigError::ParseError)
    }

    pub fn save_config(&self) -> Result<(), ConfigError> {
        if let Some(parent) = self.config_path.parent() {
            std::fs::create_dir_all(parent)?;
        }

        let content = toml::to_string_pretty(&self.config)?;
        std::fs::write(&self.config_path, content)?;

        Ok(())
    }

    pub fn get_config(&self) -> &LocalRunnerConfig {
        &self.config
    }

    pub fn update_config<F>(&mut self, updater: F) -> Result<(), ConfigError>
    where
        F: FnOnce(&mut LocalRunnerConfig),
    {
        updater(&mut self.config);
        self.save_config()
    }
}
```

## 6. ç›‘æ§å’Œæ—¥å¿—

### 6.1 å®æ—¶ç›‘æ§

```rust
use tokio::sync::broadcast;

pub struct LocalMonitor {
    event_receiver: broadcast::Receiver<ExecutionEvent>,
    metrics_collector: Arc<Mutex<MetricsCollector>>,
}

impl LocalMonitor {
    pub async fn start_monitoring(&mut self) {
        println!("ğŸš€ å¼€å§‹ç›‘æ§å·¥ä½œæµæ‰§è¡Œ...");

        while let Ok(event) = self.event_receiver.recv().await {
            self.handle_event(event).await;
        }
    }

    async fn handle_event(&self, event: ExecutionEvent) {
        match event.event_type {
            ExecutionEventType::ExecutionStarted => {
                println!("â–¶ï¸  æ‰§è¡Œå¼€å§‹: {}", event.execution_id);
            }
            ExecutionEventType::NodeStarted => {
                if let Some(node_name) = event.data.get("node_name") {
                    println!("  ğŸ”„ èŠ‚ç‚¹å¼€å§‹: {}", node_name);
                }
            }
            ExecutionEventType::NodeCompleted => {
                if let Some(duration) = event.data.get("duration_ms") {
                    println!("  âœ… èŠ‚ç‚¹å®Œæˆï¼Œè€—æ—¶: {}ms", duration);
                }
            }
            ExecutionEventType::NodeFailed => {
                if let Some(error) = event.data.get("error") {
                    println!("  âŒ èŠ‚ç‚¹å¤±è´¥: {}", error);
                }
            }
            ExecutionEventType::ExecutionCompleted => {
                if let Some(duration) = event.data.get("duration_ms") {
                    println!("ğŸ‰ æ‰§è¡Œå®Œæˆï¼Œæ€»è€—æ—¶: {}ms", duration);
                }
            }
            ExecutionEventType::ExecutionFailed => {
                println!("ğŸ’¥ æ‰§è¡Œå¤±è´¥");
            }
            _ => {}
        }

        // æ”¶é›†æŒ‡æ ‡
        let mut collector = self.metrics_collector.lock().await;
        collector.record_event(&event);
    }
}
```

è¿™ä¸ªæœ¬åœ°è¿è¡Œå™¨è®¾è®¡ä¸º Hetumind ç³»ç»Ÿæä¾›äº†å®Œæ•´çš„æœ¬åœ°å¼€å‘å’Œè°ƒè¯•ç¯å¢ƒï¼Œæ”¯æŒäº¤äº’å¼è°ƒè¯•ã€æ€§èƒ½åˆ†æå’Œå®æ—¶ç›‘æ§ï¼Œæ˜¯å¼€å‘è€…è¿›è¡Œå·¥ä½œæµå¼€å‘çš„ç†æƒ³å·¥å…·ã€‚
